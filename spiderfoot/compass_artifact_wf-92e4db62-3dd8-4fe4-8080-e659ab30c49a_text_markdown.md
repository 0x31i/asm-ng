# Discovering AI assets on the external attack surface

**No single purpose-built open-source tool exists today for comprehensive external AI model discovery**, but a rapidly maturing ecosystem of scanning frameworks, fingerprinting techniques, and security standards provides the building blocks to construct one. The most actionable starting point is **Tencent's AI-Infra-Guard**, which fingerprints 30+ AI framework components and covers 400+ CVEs, followed by **Protect AI's ai-exploits** Nuclei templates for ML service scanning. Cisco Talos research found **over 1,100 exposed Ollama LLM servers** using Shodan in just 10 minutes — roughly 20% responding to queries without any authentication — demonstrating the scale of the problem. Meanwhile, every major ASM vendor has added AI discovery capabilities since 2024, but almost exclusively through internal cloud API scanning (AI-SPM) rather than true outside-in detection. The gap between what's externally discoverable and what tools exist to discover it represents both a significant security blind spot and a clear opportunity.

## The open-source tooling landscape for AI reconnaissance

The tooling ecosystem splits into three tiers: dedicated AI infrastructure scanners, general security frameworks with AI-relevant modules, and research-stage projects with applicable methodologies.

**Tencent AI-Infra-Guard** (github.com/Tencent/AI-Infra-Guard, ~1,500 stars, MIT license) stands out as the most comprehensive open-source option. Built by Tencent's Zhuque Lab, it provides YAML-based fingerprint rules for **30+ AI framework components** including Ollama, Gradio, vLLM, ComfyUI, and n8n, with vulnerability detection covering 400+ known CVEs across 15+ AI components. Its architecture mirrors Nuclei's template approach — fingerprints live in `data/fingerprints/` and vulnerability rules in `data/vuln/`, making it straightforward to extend with new AI service signatures. It also includes MCP server security analysis using a ReAct agent framework and jailbreak evaluation capabilities. Deployment is Docker-based with both WebUI and CLI modes.

**Protect AI's ai-exploits** (github.com/protectai/ai-exploits, ~1,700 stars, Apache 2.0) provides the most directly usable Nuclei templates for scanning exposed ML infrastructure. These templates target real-world vulnerabilities in MLflow (LFI, unauthenticated access), Ray Dashboard (RCE), BentoML endpoints, AnythingLLM, and FastAPI-based ML services. Combined with Nuclei's scanning engine, these enable at-scale AI service discovery across large target sets. The repository also includes Metasploit modules and CSRF templates.

**NVIDIA's garak** (github.com/NVIDIA/garak, Apache 2.0) functions as an LLM vulnerability scanner with a highly modular plugin architecture (probes, detectors, generators, harnesses). While primarily designed for testing known LLM endpoints, its ability to probe any REST API with crafted inputs makes it adaptable for fingerprinting whether an endpoint is an LLM by analyzing response patterns. It supports OpenAI API, HuggingFace, Ollama, LiteLLM, Replicate, and custom REST endpoints.

**Wallarm's MCP detection template** (`mcp-jsonrpc2-ultimate-detect`) is the most notable standalone Nuclei template for AI infrastructure detection. It probes for exposed Model Context Protocol servers via JSON-RPC 2.0 methods (`tools/list`, `resources/list`, `prompts/list`, `rpc.discover`), confirming active MCP servers that expose privileged internals. Wallarm's research found dozens of unintentionally exposed MCP deployments.

Several adjacent tools fill specific niches. **AIShield Watchtower** (Bosch, github.com/bosch-aisecurity-aishield/watchtower) automates AI model and notebook discovery within repositories — scanning GitHub, HuggingFace, and S3 for hard-coded secrets, PII, unsafe libraries, and model serialization attacks. **Protect AI's ModelScan** detects malicious code in serialized model files. The **AI Prompt Fuzzer** Burp Suite extension can serve as a de facto AI endpoint detector during web application testing by sending prompt injection payloads and analyzing responses. **graphw00f** (github.com/dolevf/graphw00f) provides an excellent methodological model — its approach of sending crafted queries to fingerprint backend engines could be directly adapted for AI/ML service fingerprinting.

For AI Bill of Materials generation, **Trusera/ai-bom** offers 13 auto-registered scanners across source code, Docker/K8s, cloud IaC, and MCP configs with output in CycloneDX 1.6, SPDX 3.0, and SARIF formats. **Cisco's ai-defense/aibom** uses static Python analysis and container image scanning with DuckDB catalog matching for AI component identification.

## How ASM platforms approach AI discovery today

A critical distinction separates **internal AI discovery** (cloud API scanning, agent-based) from **external AI discovery** (outside-in, internet-facing). Almost every major vendor has shipped the former since 2024; almost none have shipped the latter as a dedicated capability.

**Tenable One AI Exposure** (GA January 2026) represents the most integrated approach, unifying AI protection, discovery, and usage governance across SaaS, cloud, APIs, and agents. It uses a dedicated Nessus "Artificial Intelligence" plugin family with three detection methods — AI application detection, AI software vulnerability detection, and web app scanner detection. Gartner named Tenable a Leader in the 2025 Magic Quadrant for Exposure Assessment Platforms with the highest "Ability to Execute" score. **Palo Alto's Cortex Cloud AI-SPM** provides agentless scanning across Azure OpenAI, Amazon Bedrock, Google Vertex AI, and custom deployments, generating an inventory of all models, APIs, agents, training data, and inference pipelines — including a dedicated **agentic AI inventory** tracking agent permissions, tools, and MCP connections. **Microsoft Defender for Cloud** discovers an **AI Bill of Materials** from code to cloud, covering Azure OpenAI deployments, ML workspaces, AI agents, and cataloging 1,000+ SaaS GenAI applications. **Wiz AI-SPM** builds an AI-BOM on its Security Graph, enabling attack path analysis from cloud infrastructure to AI endpoints. **Qualys TotalAI** fingerprints AI software, GPUs, and LLM endpoints, then directly tests LLMs for jailbreak vulnerabilities aligned to OWASP LLM Top 10.

The only rigorous public research on **true external/internet-facing AI detection** comes from **Cisco Talos** (September 2025). Their two-stage approach queries Shodan for service banners on known AI ports, then programmatically assesses each endpoint for authentication controls. Targeting Ollama (port 11434), they identified 1,139 exposed servers — **214 actively hosting models without authentication**, the rest "dormant" but still exploitable for unauthorized model uploads. Geographic distribution showed **36.6% in the US, 22.5% in China, 8.9% in Germany**. A secondary indicator they identified: the `Server: uvicorn` HTTP header appears widely across Python-based AI inference backends. Their Python proof-of-concept code was described in pseudocode but not publicly released. They acknowledged the approach needs extension to cover Hugging Face, Triton, vLLM, and other frameworks with adaptive fingerprinting.

## Practical fingerprinting techniques for every major ML framework

Each AI serving framework leaves distinctive fingerprints across ports, API paths, response headers, and error message patterns. These signatures form the foundation for building detection modules.

**TensorFlow Serving** runs on port **8501** (REST) and **8500** (gRPC). The endpoint `GET /v1/models/{name}/metadata` returns JSON containing a `model_spec` key with `name`, `signature_name`, and `version` fields. Error messages reference `tensorflow/serving/predict`. The gRPC service name is `tensorflow.serving.PredictionService`. **NVIDIA Triton Inference Server** uses ports **8000/8001/8002** and implements the KServe v2 protocol — `GET /v2/health/ready` and `POST /v2/repository/index` (which lists all loaded models) are the strongest fingerprints. Responses include the `NV-Status` header and Prometheus metrics with the `nv_inference_*` prefix on port 8002. **TorchServe** responds to `GET /ping` with `{"status": "Healthy"}` on port **8080**, with a management API on **8081** exposing `GET /models` to list all registered models. **MLflow** is particularly dangerous — it runs **unauthenticated and unencrypted by default** on port **5000**, with `GET /api/2.0/mlflow/experiments/list` returning full experiment data.

**Ollama** on port **11434** exposes `GET /api/tags` (list models) and `POST /api/generate` (inference). **vLLM** implements the OpenAI-compatible API on port **8000** (`GET /v1/models`, `POST /v1/chat/completions`). **BentoML** serves on port **3000** with Swagger documentation at `/docs` and health checks at `/healthz`. **KServe** endpoints respond to both `/v1/models/{name}:predict` (v1) and `/v2/models/{name}/infer` (v2). The overlap of OpenAI-compatible API patterns across vLLM, LiteLLM, LocalAI, and others means that path matching alone (`/v1/chat/completions`) cannot identify the specific backend — response header analysis and error message fingerprinting become essential differentiators.

For **DNS and subdomain discovery**, organizations consistently use predictable patterns: `inference.*`, `ml.*`, `ai.*`, `model.*`, `llm.*`, `chat.*`, `copilot.*`, `predict.*`, `serving.*`, `genai.*`, and `gpu.*`. Certificate Transparency logs expose these through crt.sh queries — `curl -s "https://crt.sh/?q=%25.target.com&output=json" | jq -r '.[].name_value' | grep -iE '(inference|ml|ai|model|llm|chat|predict|gpu|triton|mlflow|serving)'` is the foundational reconnaissance command. Cloud provider patterns are also discoverable: `*.sagemaker.<region>.amazonaws.com`, `*.inference.<region>.azurecontainer.io`, `*.endpoints.huggingface.cloud`.

**JavaScript analysis** reveals embedded AI integrations through SDK imports (`openai`, `@anthropic-ai/sdk`, `@vercel/ai`), API key patterns (`sk-*` for OpenAI, `hf_*` for HuggingFace, `sk-ant-*` for Anthropic), chat widget markers (`window.__ada`, `window.voiceflow`, `chatbase.co/embed`), and API endpoint references in bundled code. **Shodan dorks** provide rapid internet-wide discovery: `http.title:"MLflow" port:5000`, `"tritonserver" port:8000`, `port:11434 "Ollama"`, `"v2/models" port:8000`, and `http.title:"Jupyter" port:8888`.

## The frameworks defining AI attack surfaces

**MITRE ATLAS** (Adversarial Threat Landscape for AI Systems) is the primary adversarial framework, now encompassing **15 tactics, 66 techniques, 46 sub-techniques, and 33 case studies** as of October 2025, including 14 new agentic AI techniques. The Reconnaissance tactic (**AML.TA0002**) maps directly to external AI discovery, with key techniques including **AML.T0013** (Discover ML Model Ontology — identifying architecture, inputs/outputs, and operational characteristics), **AML.T0014** (Discover ML Model Family — identifying vendor or architecture to tailor attacks), **AML.T0000** (Search Victim's Publicly Available Research Materials), and **AML.T0003** (Search Victim-Owned Websites). The ML Model Access tactic (**AML.TA0004**) describes how adversaries gain access through inference APIs. Tools implementing ATLAS include Promptfoo (which maps plugins to specific techniques via `redteam: plugins: - mitre:atlas`), HiddenLayer MLDR, and MISP Galaxy's machine-readable ATLAS attack patterns.

**OWASP** maintains a constellation of overlapping AI security projects. The **AI Exchange** (owaspai.org) is the most comprehensive — 300+ pages covering all AI types with threat taxonomies organized by lifecycle stage. The **LLM Top 10 (2025)** identifies system prompt leakage (LLM07), excessive agency (LLM06), and vector/embedding vulnerabilities (LLM08) as directly relevant to attack surface discovery. The **Top 10 for Agentic Applications (December 2025)** defines four interconnected attack surface domains: the model layer, the tool ecosystem, memory architecture, and agent-to-agent communication. The **AIBOM project** establishes standards for AI supply chain transparency using CycloneDX 1.6 and SPDX 3.0 profiles. The **MAESTRO framework** provides a seven-layer architecture model for threat modeling multi-agent systems.

**NIST AI RMF 1.0** and its GenAI companion (**AI 600-1**, updated December 2025) explicitly call for organizations to "discover and inventory all AI applications" as the second step in AI governance. The framework's GOVERN function encompasses AI accountability and inventory, while MAP documents AI use cases and supply chain dependencies. **Gartner's AI TRiSM** (Trust, Risk, and Security Management) defines AI model discovery as foundational to its four-layer pyramid, noting that "security management refers to the requirement to secure the expanded surface area of AI from malicious actors."

## Building an AI discovery module for a custom ASM platform

An integration-ready AI discovery module should combine four detection layers, each implementable with existing open-source components.

The **first layer — passive internet scanning** — uses Shodan and Censys APIs to query for known AI service ports and banners. The Cisco Talos methodology provides the template: Shodan queries for ports 11434 (Ollama), 8000 (Triton/vLLM), 8501 (TF Serving), 8080 (TorchServe), 8081 (TorchServe management), 5000 (MLflow), 3000 (BentoML), 7860 (Gradio), 8501 (Streamlit), 8265 (Ray Dashboard), and 1234 (LM Studio), filtered by organization-specific IP ranges. The `Server: uvicorn` header serves as a broad secondary indicator for Python-based AI backends.

The **second layer — active fingerprinting** — adapts Tencent AI-Infra-Guard's YAML fingerprint rules or custom Nuclei templates to probe discovered hosts with framework-specific requests. A minimal probe set for each framework: `GET /v2/health/ready` (Triton), `GET /v1/models` (TF Serving/OpenAI-compatible), `GET /ping` expecting "Healthy" (TorchServe), `GET /api/2.0/mlflow/experiments/list` (MLflow), `GET /api/tags` (Ollama), `GET /healthz` (BentoML), and Wallarm's JSON-RPC probes for MCP servers. The graphw00f pattern — sending crafted requests designed to elicit framework-specific error messages — enables differentiation when multiple frameworks share the same ports.

The **third layer — subdomain and certificate discovery** — enumerates AI-related subdomains through CT logs (crt.sh, Censys), DNS brute-forcing with an AI-specific wordlist, and cloud provider pattern matching. Pipe results through httpx for liveness checking, then into the active fingerprinting layer.

The **fourth layer — web content analysis** — crawls discovered web assets to detect embedded AI integrations: JavaScript SDK imports, chat widget markers, API endpoint references, and leaked API keys. Wappalyzer-style technology fingerprinting extended with AI-specific signatures covers the detection of frontend AI integrations that don't expose backend infrastructure directly.

The most practical integration path starts with **AI-Infra-Guard as the scanning core** (its YAML fingerprint system is directly extensible), supplemented by **ai-exploits Nuclei templates** for vulnerability-specific detection, **garak** for LLM endpoint validation and probing, and a custom CT log/subdomain module built on subfinder and crt.sh APIs. Map all findings to **MITRE ATLAS technique IDs** for standardized reporting and align with the **OWASP AI Exchange** taxonomy for risk classification.

## Conclusion

The external AI attack surface discovery space is where traditional web application scanning was circa 2010 — the targets are proliferating faster than the tooling to find them. Tencent's AI-Infra-Guard and Protect AI's Nuclei templates provide the strongest open-source foundations today, while the Cisco Talos Shodan research validates the methodology. The critical gap remains a unified, modular tool that combines passive scanning, active fingerprinting, subdomain enumeration, and web content analysis specifically for AI infrastructure — analogous to what Amass or Subfinder did for subdomain discovery. Every major ASM vendor has added "AI discovery" since 2024, but this is overwhelmingly internal cloud scanning (AI-SPM), not true outside-in detection. Organizations building custom ASM platforms should treat AI-Infra-Guard's fingerprint database as the starting asset, extend it with the comprehensive API path wordlists and Shodan dorks documented in this report, and frame the capability using MITRE ATLAS reconnaissance techniques for consistent threat modeling. The AI BOM ecosystem (Trusera ai-bom, Cisco AIBOM, OWASP AIBOM Generator) provides an adjacent but complementary capability for cataloging discovered AI components in standardized formats.